<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://achchg.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://achchg.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-03-18T20:32:10+00:00</updated><id>https://achchg.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">How to run LLMs locally on your machine?</title><link href="https://achchg.github.io/blog/2024/Ollama/" rel="alternate" type="text/html" title="How to run LLMs locally on your machine?"/><published>2024-03-12T00:00:00+00:00</published><updated>2024-03-12T00:00:00+00:00</updated><id>https://achchg.github.io/blog/2024/Ollama</id><content type="html" xml:base="https://achchg.github.io/blog/2024/Ollama/"><![CDATA[<p>One of the questions I had when first started working with LLMs was around local development to support quick prototyping without worrying much of the cost (e.g. I’m still protytping for the GenAI usecase, I’d need to test the engineering pipeline multiple times which might lead to multiple prompt requests == “$$”.) or data privacy (e.g. What if I do not feel comfortable sharing my datasets, chat histories through OpenAI or Huggingface API calls to connect to remotely hosted LLMs?)</p> <p>In particular, I have experienced trying out <a href="https://gpt4all.io/index.html">GPT4ALL</a> and <a href="https://ollama.com">Ollama</a>. Here are some documentations:</p> <h4 id="gpt4all-github">GPT4ALL (<a href="https://github.com/nomic-ai/gpt4all">Github</a>)</h4> <ul> <li> <p>This was the very first approach I tried. It was easy to setup, and it also provides a chat client available for downloads. I only tried the backend API by installing gpt4all and langchain. After that, we can download and try different LLMs model on the GPT4ALL leaderboard.</p> </li> <li> <p>We can directly run GPT4 model with python using gpt4all (<a href="https://docs.gpt4all.io">documentation</a>) or using Langchain (<a href="https://python.langchain.com/docs/integrations/llms/gpt4all">documentation</a>):</p> <pre><code class="language-{python}">from langchain_community.llms import GPT4All
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate
from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler

local_path = 'path to where you save the model bin file'
llm = GPT4All(model=local_path, callbacks=[StreamingStdOutCallbackHandler()])

template = """{question}"""

prompt = PromptTemplate.from_template(template)
llm_chain = LLMChain(prompt=prompt, llm=llm)
question = "What would be a good time to eat lunch?"

llm_chain.run(question)
</code></pre> </li> </ul> <h4 id="ollama-github">Ollama (<a href="https://github.com/ollama/ollama">Github</a>)</h4> <ul> <li> <p>Very easy to setup. I followed the quickstart steps to install ollama on my Mac, and then run ollama docker image to start my local container. After these steps, I’m able to pull or run different LLMs available on their leaderboard.</p> </li> <li>We can directly run Ollama models from Terminal after setup: <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ollama run llama2 "What would be a good time to eat lunch?"
</code></pre></div> </div> </li> <li>If need to further develop with python, it is also well integrated with Langchain: <pre><code class="language-{python}">from langchain_community.llms import Ollama
from langchain_community.chat_models import ChatOllama
from langchain_core.messages import HumanMessage

llm = Ollama(model="llama2")
chat_model = ChatOllama()

text = "What would be a good time to eat lunch?"
messages = [HumanMessage(content=text)]

llm.invoke(text)
</code></pre> </li> </ul>]]></content><author><name></name></author><category term="llm"/><category term="learn"/><summary type="html"><![CDATA[One of the questions I had when first started working with LLMs was around local development to support quick prototyping without worrying much of the cost (e.g. I’m still protytping for the GenAI usecase, I’d need to test the engineering pipeline multiple times which might lead to multiple prompt requests== “$$”.) or data privacy (e.g. What if I do not feel comfortable sharing my datasets, chat histories through OpenAI or Huggingface API calls to connect to remotely hosted LLMs?)]]></summary></entry><entry><title type="html">NBeats</title><link href="https://achchg.github.io/blog/2022/NBeats/" rel="alternate" type="text/html" title="NBeats"/><published>2022-11-15T00:00:00+00:00</published><updated>2022-11-15T00:00:00+00:00</updated><id>https://achchg.github.io/blog/2022/NBeats</id><content type="html" xml:base="https://achchg.github.io/blog/2022/NBeats/"><![CDATA[<p>Finally got chance to jog down some notes around the <a href="https://arxiv.org/pdf/1905.10437.pdf">N-BEATS</a> paper.</p> <h4 id="main-contributions">Main contributions</h4> <ul> <li>1) <strong>deep neural architecture</strong>: Pure deep learning network without time-series specific componets that performed better than well-established statistical models on reference time-series datasets (e.g. M3, M4, etc.).</li> <li>2) <strong>interpretable DL for time series</strong></li> </ul> <h4 id="algorithm">Algorithm</h4> <ul> <li><strong>Task:</strong> Predict the vector of future values (\(\mathbb{y} = [y_{T+1}, y_{T+2}, ..., y_{T+H}]\)) of length H forecast horizon given a length T observed historical series \([y_{1}, y_{2}, ..., y_{T}]\). <ul> <li>if define a lookback window of length t \(\leq\) T from \(y_T\), the model period can be denoted as \(\mathbb{x} = [y_{T-t+1}, y_{T-t+2}, ..., y_{T}]\)</li> <li>the forecasts are \(\hat{\mathbb{y}}\)</li> <li>Common evaluation metrics for time-series forecasts are: <ul> <li><strong>MAPE (mean absolute percentage error):</strong> \(\frac{100}{H}\sum_{i=1}^H \frac{\left| y_{T+i}-\hat{y}_{T+i} \right| }{|y_{T+i}|}\) (the errors are scaled by the ground truth)</li> <li><strong>SMAPE (symmetric MAPE):</strong> \(\frac{200}{H}\sum_{i=1}^H \frac{\left| y_{T+i}-\hat{y}_{T+i} \right| }{|y_{T+i}| + |\hat{y}_{T+i}|}\) (the errors are scaled by the average of forecast and ground truth)</li> <li><strong>MASE (mean absolute scaled error):</strong> \(\frac{1}{H}\sum_{i=1}^H \frac{\left| y_{T+i}-\hat{y}_{T+i} \right| }{\frac{1}{T+H-m} \sum_{j=m+1}^{T+H}|y_j - y_{j-m}|}\) (the errors are scaled by the average error measured m periods in the past, accounting for seasonality)</li> </ul> </li> </ul> </li> <li><strong>Architecture:</strong></li> </ul> <div class="row justify-content-sm-center"> <div class="col-sm-12 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/nbeats-480.webp 480w,/assets/img/nbeats-800.webp 800w,/assets/img/nbeats-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/nbeats.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="nbeats image" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <ul> <li><strong>Basic block: (blue figure)</strong> Take 1 Block input vector (\(x_l\)) and output 2 vectors: \(\hat{x_l}\), the backcast (usually with length of 2H - 7H) + \(\hat{y_l}\), the forecast (usually with length of H) <ul> <li>Block 1’s input is the overall model input (\(x_l\)): lookback values within the defined window (\(x_l\))</li> <li>Block 2 - L’s input is the the backcast <strong>residual</strong> values from the previous layer (\(x_l\) = \(x_{l-1} - \hat{x}_{l-1}\))</li> <li>Within the Block, the default algorithm is consist of 4 standard fully-connected (FC) layers with ReLU non-linearity stacking in sequence with 2 linear output layers.</li> </ul> </li> <li><strong>Doubly residual stacking (orange+yellow figure):</strong> An extension from the classic <a href="https://achchg.github.io/blog/2022/ResNet/">ResNet</a> architecture, e.g. Input vector (x) is added to the output vector (F(x)) before passing to the next stack. The proposed architecture involved the two residual branches (forecast and backcast) as described in above section within each block, and stack the residues between blocks with the following two equations: <ul> <li>Backcast residual branch, each depending on residues from previous block: \(x_l\) = \(x_{l-1} - \hat{x}_{l-1}\)</li> <li>Forecast residual branch, summation of forecasts by all blocks within a stack: \(\hat{y} = \sum_l \hat{y}_l\)</li> <li>Both equations are repeated as the same architecture across stacks and the final forecasts are the summation of \(\hat{y}\)</li> </ul> </li> <li>Aboves were notes over a generic model setup <strong>without</strong> time-series specific knowledge on none-linear trend or seasonality (a.k.a the assumptions on \(g_b\) and \(g_f\) specified in the cartoon figure were linear). That says, with additional assumptions made on the two equations across blocks/stacks, we’re also able to incorporate TS-specific assumptions in for tuning.</li> </ul> <p>Helpful videos &amp; blogs:</p> <ul> <li><a href="https://www.youtube.com/watch?v=ZILIbUvp5lk">ResNets</a> and <a href="https://www.youtube.com/watch?v=RYth6EbBUqM&amp;list=PLkDaE6sCZn6Gl29AoE31iwdVwSG-KnDzF&amp;index=15">Why ResNets work</a> by DeepLearningAI</li> <li><a href="https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035">An Overview of ResNet and its Variants</a></li> </ul>]]></content><author><name></name></author><category term="dl"/><category term="learn"/><summary type="html"><![CDATA[Day 55]]></summary></entry><entry><title type="html">SQL</title><link href="https://achchg.github.io/blog/2022/SQL/" rel="alternate" type="text/html" title="SQL"/><published>2022-10-25T00:00:00+00:00</published><updated>2022-10-25T00:00:00+00:00</updated><id>https://achchg.github.io/blog/2022/SQL</id><content type="html" xml:base="https://achchg.github.io/blog/2022/SQL/"><![CDATA[<p>Helpful SQL practice resources:</p> <h1 id="knowledge-refreshes">Knowledge refreshes</h1> <ul> <li><a href="https://e2eml.school/sql_resources.html">e2eml.school</a> has a lot of great resources shared</li> <li><a href="https://learn.udacity.com/courses/ud198">SQL for Data Analysis</a> by Udacity includes basic to advanced SQL tutorials</li> <li><a href="https://www.youtube.com/watch?v=zrCLRC3Ci1c">Lecture 7: SQL</a> by CS50</li> <li><a href="https://www.interviewquery.com/p/data-science-sql-interview-questions">Top 25+ Data Science SQL Interview Questions</a></li> </ul> <h1 id="practice-examples">Practice examples</h1> <ul> <li><a href="https://leetcode.com/study-plan/sql/?progress=xanj57th">Leetcode Study Plan</a></li> <li><a href="https://sqlbolt.com">SQLBolt</a></li> </ul>]]></content><author><name></name></author><category term="sql"/><category term="review"/><summary type="html"><![CDATA[Day 33]]></summary></entry><entry><title type="html">Attention</title><link href="https://achchg.github.io/blog/2022/Attention/" rel="alternate" type="text/html" title="Attention"/><published>2022-10-24T00:00:00+00:00</published><updated>2022-10-24T00:00:00+00:00</updated><id>https://achchg.github.io/blog/2022/Attention</id><content type="html" xml:base="https://achchg.github.io/blog/2022/Attention/"><![CDATA[<p>There are a lot of nice materials explaining Attention model fairly well. My favorite have been <a href="https://distill.pub/2016/augmented-rnns/#attentional-interfaces">the “Attention Interfaces” of this blog post</a> and the <a href="https://web.stanford.edu/class/cs224n/readings/cs224n-2019-notes06-NMT_seq2seq_attention.pdf">CS224N lecture note</a>.</p> <h4 id="attention">Attention</h4> <p>Great <a href="https://www.youtube.com/watch?v=SysgYptB198">video</a> with the intuition of Attention model explained by Andrew Ng.</p> <p>Typical sequence-to-sequence models like RNN were used in machine translation, where a input sentence of language A is translated to an output sentence of target language B in an encoder-decoder architecture. One problem with it was that the models go word by word within a sentence during encoding and depending on the final hidden layer before decoding to memorize everything fed into the system for translation; the decoder than taking the hidden layer and pass on another sequence to predict the most likely word that should pop up next given the current translated word.</p> <p>On the contrary, the decoder network (language B) of the Attention model was trained by <strong>the entire input sequence</strong> (language A) at every decoding step (y_t) with the goal of learning the <strong>attention weight</strong> (\(\alpha_{t,1}\) to \(\alpha_{t,T}\)) of individual translated word in B on all the input words (x_1, …, x_T) in A. Below cited the Figure 1 from the <a href="https://arxiv.org/pdf/1409.0473.pdf">original Attention paper</a>.</p> <div class="row"> <div class="col-md-3 offset-md-3"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/attention-480.webp 480w,/assets/img/attention-800.webp 800w,/assets/img/attention-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/attention.png" width="100%" height="auto" title="example image" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Great video materials:</p> <ul> <li><a href="https://www.youtube.com/watch?v=quoGRI-1l0A">Attention model</a> by Andrew Ng.</li> </ul>]]></content><author><name></name></author><category term="ml,"/><category term="dl"/><category term="review"/><summary type="html"><![CDATA[Day 32]]></summary></entry><entry><title type="html">Gradient boosting</title><link href="https://achchg.github.io/blog/2022/Gradient_boosting/" rel="alternate" type="text/html" title="Gradient boosting"/><published>2022-10-14T00:00:00+00:00</published><updated>2022-10-14T00:00:00+00:00</updated><id>https://achchg.github.io/blog/2022/Gradient_boosting</id><content type="html" xml:base="https://achchg.github.io/blog/2022/Gradient_boosting/"><![CDATA[<p>While looking at <a href="https://achchg.github.io/blog/2022/ResNet/">ResNets</a>, One thought came to my mind - “So isn’t this boosting?”. An immediate next step of researching this topic led me to this stackoverflow <a href="https://stats.stackexchange.com/questions/214273/are-residual-networks-related-to-gradient-boosting">discussion</a>, and later a review session of gradient boosting algorithms.</p> <h4 id="gradient-boosting">Gradient boosting</h4> <p>Actually the Wikipedia <a href="https://en.wikipedia.org/wiki/Gradient_boosting">page</a> of gradient boosting summarizes the algorithm fairly well. High-level description of what it is with my own words:</p> <p><strong>“An additive model of weaker trees with forward feature selection trained by gradient descent method that aims to learn to avoid making errors made in previous stages (trees).”</strong></p> <p>How gradient boosting works:</p> <ol> <li> <p>Define a boosting tree (\(F_M\)) that we aim for \(M\) stages (M weak learners/trees): \(\hat{F}_M(x_i) = \Sigma_{m=1}^M \alpha_m h_m(x_i) + \text{const.}\) where \(\alpha_m\) is the learning rate.</p> </li> <li>Define loss at the \(m^{th}\) stage/base learner: <ul> <li>loss function: \(L(y, F_m(x))\)</li> <li>example base learner: \(h_m(x_i) = y_i - \hat{y}_{i,m} = y_i - F_m(x_i)\)</li> <li>goal is to minimize the loss</li> </ul> </li> <li> <p>At stage 0, as there was no stage before it. Therefore, in the very first tree, we are fitting the tree with \(y_i\) directly: \(F_0(x_i) = \arg \min_\alpha \Sigma_{i=1}^n L(y_i, \alpha)\)</p> </li> <li> <p>At stage \(m\) (where \(m \neq 0\)), we are fitting the \(m^{th}\) tree with the residual: \(F_m(x_i) = F_{m-1}(x_i) + \arg \min_{h_m} \Sigma_{i=1}^n L(y_i, F_{m-1}(x_i) + \alpha h_m(x_i))\)</p> </li> <li>Repeat #4 and keep updating the model until convergence (\(F_m(x_i) = F_{m-1}(x_i) + \alpha_mh_m(x_i)\)).</li> </ol> <p>Also, nicely explained source for boosting algorithm by <a href="https://c.d2l.ai/stanford-cs329p/_static/pdfs/cs329p_slides_7_3.pdf">CS 329P : Practical Machine Learning (2021 Fall)</a>:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre></td><td class="code"><pre> <span class="k">class</span> <span class="nc">GradientBoosting</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">base_learner</span><span class="p">,</span> <span class="n">n_learners</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">learners</span> <span class="o">=</span> <span class="p">[</span><span class="nf">clone</span><span class="p">(</span><span class="n">base_learner</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">n_learners</span><span class="p">)]</span>
        <span class="n">self</span><span class="p">.</span><span class="n">lr</span> <span class="o">=</span> <span class="n">learning_rate</span>
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">residual</span> <span class="o">=</span> <span class="n">y</span><span class="p">.</span><span class="nf">copy</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">learner</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">learners</span><span class="p">:</span>
            <span class="n">learner</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">residual</span><span class="p">)</span>
            <span class="n">residual</span> <span class="o">-=</span> <span class="n">self</span><span class="p">.</span><span class="n">lr</span> <span class="o">*</span> <span class="n">learner</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="n">X</span><span class="p">):</span>
        <span class="n">preds</span> <span class="o">=</span> <span class="p">[</span><span class="n">learner</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="k">for</span> <span class="n">learner</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">learners</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">preds</span><span class="p">).</span><span class="nf">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">lr</span>
</pre></td></tr></tbody></table></code></pre></figure> <p>Here, we can leverage different base_learner (e.g. regression or classification models with differen objective functions)</p> <h5 id="gradient-boosting-regression">Gradient boosting regression</h5> <p><strong>Loss function:</strong> MSE!</p> \[\begin{align*} L(y, F_m(x_i)) &amp; = \frac{1}{n}\Sigma_{i=1}^n(F_m(x_i)-y_i)^2\\ \arg \min_{F_m} \Sigma_{i=1}^n L(y_i, F_m) &amp; = -\frac{\partial L(y, F_m(x_i))}{\partial F_m} \propto \Sigma_{i=1}^n(y_i-F_m(x_i)) \rightarrow \boxed{r_m = \text{pseudo-residual}}\\ \arg \min_{\gamma} L(y, F_{m-1}(x_i)+\gamma) &amp;\approx \arg \min_{\gamma} [L(y, F_{m-1}(x_i)) +\frac{\partial L(y, F_{m-1}(x_i))}{\partial F}\gamma +\frac{1}{2}\frac{\partial^2 L(y, F_{m-1}(x_i))}{\partial F^2}\gamma^2]\\ &amp; = 0 + \frac{\partial L(y, F_{m-1}(x_i))}{\partial F} + \frac{\partial^2 L(y, F_{m-1}(x_i))}{\partial F^2}\gamma \stackrel{\text{set}}{=} 0\\ \gamma &amp; = - \frac{\frac{\partial L(y, F_{m-1}(x_i))}{\partial F}}{\frac{\partial^2 L(y, F_{m-1}(x_i))}{\partial F^2}} = \boxed{\frac{\Sigma_{i=1}^n y_i - F_m(x_i)}{n}} \end{align*}\] <p><strong>Source <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html#sklearn.ensemble.GradientBoostingRegressor">code</a> from sklearn</strong></p> <p>Great video materials:</p> <ul> <li><a href="https://www.youtube.com/watch?v=2xudPOBz-vs">StatQuest</a></li> </ul> <h5 id="gradient-boosting-classification">Gradient boosting classification</h5> <p><strong>Loss function:</strong> Can use the same as logistic regression, details illustrated <a href="https://achchg.github.io/blog/2022/Stochastic_gradient_descent/">here</a>.</p> \[\begin{align*} L(y, F_m(x_i)) &amp; = \Pi_{i=1}^n F_m(x_i)^y_i(1-F_m(x_i))^{1-y_i}\\ \ell(y, F_m(x_i)) &amp; = \Sigma_{i=1}^n [y_i\log(F_m(x_i)) + (1-y_i)\log(1-F_m(x_i))] \\ &amp; = \Sigma_{i=1}^n y_i\log(\frac{F_m(x_i)}{1-F_m(x_i)}) + \log(1-F_m(x_i))\\ &amp; = \Sigma_{i=1}^n y_i\log(\text{Odds}) + \log(1-\frac{\exp(\log(\text{Odds}))}{1+\exp(\log(\text{Odds}))})\\ &amp; = \Sigma_{i=1}^n y_i\log(\text{Odds}) - \log(1+\exp(\log(\text{Odds})))\\ \arg \min_{\log(\text{Odds})} \ell(y, F_m(x_i)) &amp;= \frac{\partial \ell(y, F_m(x_i))}{\partial \log(\text{Odds})} = \Sigma_{i=1}^n y_i - \frac{\exp(\log(\text{Odds}))}{1+\exp(\log(\text{Odds}))} \\ &amp;= \Sigma_{i=1}^n y_i - F_m(x_i) \rightarrow \boxed{r_m = \text{pseudo-residual}}\\ \arg \min_{\gamma} \ell(y, F_{m-1}(x_i)+\gamma) &amp;\approx \arg \min_{\gamma} [\ell(y, F_{m-1}(x_i)) +\frac{\partial \ell(y, F_{m-1}(x_i))}{\partial F}\gamma +\frac{1}{2}\frac{\partial^2 \ell(y, F_{m-1}(x_i))}{\partial F^2}\gamma^2]\\ &amp; = 0 + \frac{\partial \ell(y, F_{m-1}(x_i))}{\partial F} + \frac{\partial^2 \ell(y, F_{m-1}(x_i))}{\partial F^2}\gamma \stackrel{\text{set}}{=} 0\\ \gamma &amp; = - \frac{\frac{\partial \ell(y, F_{m-1}(x_i))}{\partial F}}{\frac{\partial^2 \ell(y, F_{m-1}(x_i))}{\partial F^2}} = \boxed{\frac{\Sigma_{i=1}^n y_i - F_m(x_i)}{\Sigma_{i=1}^n F_m(x_i)*(1-F_m(x_i))}} \end{align*}\] <p><strong>Source <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#sklearn.ensemble.GradientBoostingClassifier">code</a> from sklearn</strong></p> <p>Great video materials:</p> <ul> <li><a href="https://www.youtube.com/watch?v=StWY5QWMXCw">StatQuest</a></li> </ul> ]]></content><author><name></name></author><category term="ml,"/><category term="boosting,"/><category term="gradient"/><category term="review"/><summary type="html"><![CDATA[Day 22]]></summary></entry><entry><title type="html">ResNets</title><link href="https://achchg.github.io/blog/2022/ResNet/" rel="alternate" type="text/html" title="ResNets"/><published>2022-10-10T00:00:00+00:00</published><updated>2022-10-10T00:00:00+00:00</updated><id>https://achchg.github.io/blog/2022/ResNet</id><content type="html" xml:base="https://achchg.github.io/blog/2022/ResNet/"><![CDATA[<p>I recently found a paper regarding time-series forecasting: <a href="https://arxiv.org/pdf/1905.10437.pdf">N-BEATS</a> and found myself missing a few pre-requsite concept. One of them was the use of classic residual network algorithm, first proposed as <a href="https://arxiv.org/pdf/1512.03385.pdf">ResNets</a>. Here are some of my learning notes:</p> <h4 id="resnets">ResNets</h4> <p>A residual neural network (<a href="https://en.wikipedia.org/wiki/Residual_neural_network">ResNet</a>) is a deep neural netword architecture, which uses skip connections/shortcuts to jump over some layers (usually 2-3 layer skips) to avoid the problems of:</p> <ul> <li>1) <strong>vanishing/exploding gradients</strong>: gradients becoming too small or big when increasing layers, and</li> <li>2) <strong>degradation</strong>: deeper NN has larger training/testing error.</li> </ul> <p>ResNets contain typical NN characteristics of adding nonlinearities (ReLU) and batch normalization in between the layers. Note that the residual (\(F(x)\)) of a residual block will be add to an identity matrix (\(x\)) before passing on to the ReLU activation function.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/residual_block-480.webp 480w,/assets/img/residual_block-800.webp 800w,/assets/img/residual_block-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/residual_block.png" width="100%" height="auto" title="example image" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Why it solves the 2 problems above?</p> <ul> <li>If considering a NN above, then \(F(x) + x = a^{[2]} = g(z^{[2]} + x) = g(w^{[2]} a^{[1]} + b^{[2]} + x)\).</li> <li>To solve the above equation by minimizing \(F(x)\) as 0, we’d get \(a^{[2]} = x \approx g(x)\), where we expect \(w^{[2]} \approx 0\) and \(b^{[2]} \approx 0\) so as \(w^{[l]}\) and \(b^{[l]}\) at earlier layers (l).</li> </ul> <p>Example pytorch resource for ResNet18 is <a href="https://pytorch.org/hub/pytorch_vision_resnet/">here</a></p> <p>Original ResNets paper is <a href="https://arxiv.org/pdf/1512.03385.pdf">here</a>.</p> <p>Helpful videos &amp; blogs:</p> <ul> <li><a href="https://www.youtube.com/watch?v=ZILIbUvp5lk">ResNets</a> and <a href="https://www.youtube.com/watch?v=RYth6EbBUqM&amp;list=PLkDaE6sCZn6Gl29AoE31iwdVwSG-KnDzF&amp;index=15">Why ResNets work</a> by DeepLearningAI </li> </ul>]]></content><author><name></name></author><category term="dl"/><category term="image"/><category term="learning"/><summary type="html"><![CDATA[Day 18]]></summary></entry><entry><title type="html">RNN/LSTM</title><link href="https://achchg.github.io/blog/2022/RNN/" rel="alternate" type="text/html" title="RNN/LSTM"/><published>2022-10-07T00:00:00+00:00</published><updated>2022-10-07T00:00:00+00:00</updated><id>https://achchg.github.io/blog/2022/RNN</id><content type="html" xml:base="https://achchg.github.io/blog/2022/RNN/"><![CDATA[<p>My notes from reviewing RNN model in NLP, following the flow of <a href="https://web.stanford.edu/class/cs224n/readings/cs224n-2019-notes05-LM_RNN.pdf">RNN</a> and <a href="https://web.stanford.edu/class/cs224n/readings/cs224n-2019-notes06-NMT_seq2seq_attention.pdf">Seq2seq</a> lecture notes.</p> <h4 id="rnn-architecture">RNN architecture</h4> <p>I’ll use the below figure cited from CS224n lecture 5-6 notes of RNN to summarize RNN:</p> <p>“The elements (e.g. words) were fed into the algorithm one after one along (e.g. the \(t^{th}\) element of the input sequence, \(w_{t}\)) with the hidden output layer (\(h_{t-1}\)) from the previous timestamp (\(t-1\)) in predicting the most likely next element of the output sequence (\(y_{t}\))”</p> \[\begin{align*} h_t &amp; = \sigma(W^{(hh)}h_{t−1} + W^{(hx)}x_{t})\\ y_t &amp; = \text{softmax}(W^{(S)}h_t) \end{align*}\] <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/rnn-480.webp 480w,/assets/img/rnn-800.webp 800w,/assets/img/rnn-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/rnn.png" width="100%" height="auto" title="example image" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <ul> <li>Parameters to be solved: \(h_t\), \(W^{(hh)}\), \(W^{(hx)}\) and \(W^{(S)}\)</li> <li>With the softmax activation function, the common loss function for RNN is the cross-entropy loss (as derived previously in the <a href="https://achchg.github.io/blog/2022/Stochastic_gradient_descent/">SGD post with logistic regression</a>):</li> </ul> \[\begin{align*} J^{(t)}(\theta) &amp;= −\Sigma_{j=1}^{|V|}y_{t,j} * log(\hat{y}_{t,j}) \\ J(\theta) &amp;= \frac{1}{T}\Sigma_{t=1}^TJ^{(t)}(\theta) \end{align*}\] <ul> <li>As the sequence is getting longer, there could be vanishing/exploding gradient problem. As we’d solve for the gradient for \(J^{(t)}(\theta)\) with chain rule with respect to multiple layers of t. The gradient can become very small or large. One way to solve the exploding gradient problem is to setup a threshold for the gradient, as the gradient exceeds the threshold, adjust the gradient to a smaller level.</li> <li>Evaluation method of RNN model: <strong>Perplexity!</strong> The lower the perplexity, the better the model.</li> </ul> \[\begin{align*} \text{perplexity} = \exp({J}) \end{align*}\] <h4 id="long-short-term-memory-lstm">Long Short Term Memory (LSTM)</h4> <p>Here is a very nicely written <a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">blog</a> and where I referenced the below figure, but I’d take my own notes below:</p> <p>“LSTM is a special form of RNN that aimed to avoid the long-term dependency problem due to long sequence.”</p> \[\begin{align*} \color{Cerulean}\text{forget gate: } &amp; \color{Cerulean}\boxed{f^{(t)} = \sigma(W_fh_{t−1} + U_fx_{t} + b_f)}\\ &amp;\color{Cerulean}\textnormal{what content from t-1 is kept, $f^{(t)}$ is between 0 and 1; larger means "memory keeping"}\\ \color{blue}\text{input gate: } &amp; \color{blue}\boxed{i^{(t)} = \sigma(W_fi_{t−1} + U_ix_{t} + b_i)}\\ \color{darkblue}\text{output gate: } &amp; \color{darkblue}\boxed{o^{(t)} = \sigma(W_fo_{t−1} + U_ox_{t} + b_0)}\\ \\ \color{Lavender} \text{new cell content: } &amp; \color{Lavender}\boxed{\tilde{c}_{t} = \tanh(W_ch_{t-1} + U_cx_{t} + b_c)}\\ \color{Purple} \text{new cell state: } &amp; \color{Purple}\boxed{c_{t} = f_{t} \cdot c_{t-1} + i_t \cdot \tilde{c}_{t}} \\ &amp;\color{Purple}\textnormal{new and carryover contents to be written}\\ \\ &amp; h_t = o_t \cdot \tanh c_t\\ &amp;\textnormal{new memory to be ouput}\\ \end{align*}\] <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/lstm-480.webp 480w,/assets/img/lstm-800.webp 800w,/assets/img/lstm-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/lstm.png" width="100%" height="auto" title="lstm image" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Nice RNN resources:</p> <ul> <li><a href="https://web.stanford.edu/class/cs224n/slides/cs224n-2022-lecture05-rnnlm.pdf">CS224N lecture 5</a></li> <li><a href="https://web.stanford.edu/class/cs224n/slides/cs224n-2022-lecture06-fancy-rnn.pdf">CS224N lecture 6</a></li> <li><a href="https://www.youtube.com/watch?v=AsNTP8Kwu80">StatQuest</a></li> </ul>]]></content><author><name></name></author><category term="dl"/><category term="sequence"/><category term="review"/><summary type="html"><![CDATA[Day 15]]></summary></entry><entry><title type="html">Adam (adaptive moment estimation) optimizer</title><link href="https://achchg.github.io/blog/2022/Adam_optimizer/" rel="alternate" type="text/html" title="Adam (adaptive moment estimation) optimizer"/><published>2022-10-04T00:00:00+00:00</published><updated>2022-10-04T00:00:00+00:00</updated><id>https://achchg.github.io/blog/2022/Adam_optimizer</id><content type="html" xml:base="https://achchg.github.io/blog/2022/Adam_optimizer/"><![CDATA[<p>Reviewing <a href="https://web.stanford.edu/class/cs224n/assignments/a3_handout.pdf">week 3 assignment</a> of NLP with deep learning brought Adam optimization algorithm back to my attention. Here I’d summarize what I did in my homework 3 for my future reference:</p> <h4 id="adam-optimizer">Adam optimizer</h4> <p>From standard SGD, we would use a mini-batch (e.g. single sample) of data in the update rule below for updating the \(J(\theta)\):</p> \[\theta := \theta - \alpha \nabla_\theta J(\theta)\] <p>where \(\alpha\) is the learning rate and \(\nabla_\theta J(\theta)\) represent the partial derivatives of the cost function wrt \(\theta\).</p> <p>Adam optimization, in addition, takes 2 additional steps beyond SGD:</p> <h5 id="update-biased-first-order-moment-estimate">Update biased first order moment estimate</h5> \[\begin{align*} m &amp; := \beta_1 m + (1 − \beta_1)\nabla_\theta J(\theta)\\ \theta &amp; := \theta - \alpha m \end{align*}\] <p>As \(m\) is set as a weighted average of the rolling gradient average of the <strong>previous</strong> iterations and the gradient of the <strong>current</strong> iteration, we can expect the <strong>momentum</strong> step making the gradient descent update smoother than that of the SGD (which only consider the <strong>current</strong> iteration). The current gradient (\(\nabla_{\theta} J(\theta)\)) will be weighted larger than the individual gradients after k (\(\frac{\beta_1}{1-\beta_1}\)) iterations, as the individual previous gradients has a weight of \(\frac{\beta_1}{k}\) (where k = num of past iterations).</p> <h5 id="update-biased-second-order-raw-moment-estimate">Update biased second order raw moment estimate</h5> \[\begin{align*} v &amp; := \beta_2 v + (1 − \beta_2)(\nabla_\theta J(\theta) \odot \nabla_\theta J(\theta))\\ \theta &amp; := \theta - \alpha \frac{m}{\sqrt{v}} \end{align*}\] <p>As \(m\) is divided by the \(\sqrt{v}\) (the gradient of Adam), the gradients that have smaller gradient magnitude (\(v\)) will get larger updates. As \(v\) is derived from squared of \(\nabla_{\theta} J(\theta)\), \(v\) is usually associated with smaller gradient. This might help further smoothing out the gradient descent from the <strong>momentum</strong> step, by giving larger weights to the smaller gradients when the SGD update does not guarantee continuous descending in the gradients.</p> <h5 id="note-method-of-moment">Note: Method of moment</h5> <p><a href="https://en.wikipedia.org/wiki/Method_of_moments_(statistics)">Method of moment</a> in statistics implies the following:</p> <p>The \(k^{th}\) moment of a random variable X with its pdf, \(f(x)\) can be expressed as:</p> \[E(X^k) = \int_X x^k f(x) dx\] <p>Therefore, the first moment of X is \(E(X)\), which is the mean of the distribution; and the second moment of X is \(E(X^2)\), which is the sum of mean squared and the variance (\(\text{Var}(X) = E(X^2) - E(X)^2\)). </p> <p>Original Adam paper is <a href="https://arxiv.org/pdf/1412.6980.pdf">here</a>; Helpful <a href="https://gregorygundersen.com/blog/2020/04/11/moments/">documentation</a> of moment statistics.</p>]]></content><author><name></name></author><category term="optimization"/><category term="gradient"/><category term="review"/><summary type="html"><![CDATA[Day 12]]></summary></entry><entry><title type="html">Stochastic gradient descent</title><link href="https://achchg.github.io/blog/2022/Stochastic_gradient_descent/" rel="alternate" type="text/html" title="Stochastic gradient descent"/><published>2022-09-29T00:00:00+00:00</published><updated>2022-09-29T00:00:00+00:00</updated><id>https://achchg.github.io/blog/2022/Stochastic_gradient_descent</id><content type="html" xml:base="https://achchg.github.io/blog/2022/Stochastic_gradient_descent/"><![CDATA[<p>I’m reviewing the gradient descent and stochastic gradient descent again with NLP in deep learning, which are common machine learning parameter optimization methods well covered by packages these days and we normally use them hand-waving. Here, I’ll use logistic regression as my example:</p> <h4 id="stochastic-gradient-descent">(Stochastic) Gradient descent</h4> <p>Our often goal to develop a ML model is to make better prediction (i.e. minimize the cost of a model, \(J(\theta)\)), where \(\theta\) is a single parameter of our model here. In gradient descent, we’d:</p> <ol> <li>randomly initiate a value for \(\theta\) at start</li> <li>use the whole sample space (or a batch of data) to calculate the cost of a model under the \(\theta\) estimation at iteration \(j\)</li> <li> <p>make the \(\theta\) estimation at the next iteration with the following algorithm (where \(\alpha\) is the learning rate): \(\theta_j := \theta_j - \alpha \frac{\partial}{\partial \theta_j}J(\theta)\)</p> </li> <li>repeat #3 until \(\theta_j\) is converged (\(J(\theta)\) is minimized)</li> </ol> <p>In stochastic gradient descent, instead, we’d repeat #1 - #3 at every single sample to approximate the gradient with single data point. This allows us to update the gradient and cost incrementally fairly quickly.</p> <h4 id="cost-of-logistic-regression">Cost of logistic regression</h4> <p>If considering a logistic regression model with the simpliest setup to classify a binary outcome \(y\) that follows a bernouli trial:</p> \[\begin{align*} y_i &amp; = \begin{cases} 1 &amp; \text{, p}\\ 0 &amp; \text{, 1-p} \end{cases} \\ y_i &amp; \sim \text{Bernouli}(p)\\ \\ f(y) &amp; = p^y(1-p)^{1-y}\\ \\ L(y) &amp; = \Pi_{i=1}^n p^y_i(1-p)^{1-y_i} \end{align*}\] \[\begin{align*} \text{logit}(p) &amp; = \alpha + \beta x_i \\ p_i &amp; = \frac{\exp(\alpha + \beta x_i)}{1 + \exp(\alpha + \beta x_i)} \end{align*}\] <p>Therefore, we can derive the log-likelihood function:</p> \[\begin{align*} \ell(y) &amp; = \Sigma_{i=1}^n y_i\log(p_i) + (1-y_i)\log(1-p_i)\\ &amp; = \Sigma_{i=1}^n \log(1-p_i) + y_i\log(\frac{p_i}{1-p_i})\\ &amp; = \Sigma_{i=1}^n -\log(1 + \exp(\alpha + \beta x_i)) + y_i(\alpha + \beta x_i)\\ \end{align*}\] <p>If we use the negative average log-likelihood (cross entropy) as the cost function (J) would be:</p> \[J = -\frac{1}{n}\Sigma_{i=1}^n y_i(\alpha + \beta x_i) + \log(1 + \exp(\alpha + \beta x_i))\] <p>And the gradients of \(\alpha\) and \(\beta\) are:</p> \[\begin{align*} \frac{\partial}{\partial \alpha} &amp; = -\frac{1}{n}\Sigma_{i=1}^n y_i +\frac{\exp(\alpha + \beta x_i)}{1 + \exp(\alpha + \beta x_i)} = \frac{1}{n}\Sigma_{i=1}^n(p_i-y_i) = \frac{1}{n}\Sigma_{i=1}^n(\hat{y_i}-y_i)\\ \frac{\partial}{\partial \beta} &amp; = -\frac{1}{n}\Sigma_{i=1}^n y_ix_i +\frac{\exp(\alpha + \beta x_i) x_i}{1 + \exp(\alpha + \beta x_i)}= \frac{1}{n}\Sigma_{i=1}^n x_i(p_i-y_i) = \frac{1}{n}\Sigma_{i=1}^n x_i(\hat{y_i}-y_i) \end{align*}\] <p>With gradient descent, we’d optimize \(\alpha\) and \(\beta\) with the following algorithm and learning rates:</p> \[\begin{align*} \alpha_j &amp; := \alpha_j - \eta_1 \frac{1}{n}\Sigma_{i=1}^n(\hat{y_i}-y_i)\\ \beta_j &amp; := \beta_j - \eta_2 \frac{1}{n}\Sigma_{i=1}^nx_i(\hat{y_i}-y_i) \end{align*}\] <p>Pseudo code that I wrote from CS224 assignment. Here x is the parameter to be optimized and step is the learning rate:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
3
4
</pre></td><td class="code"><pre> <span class="k">for</span> <span class="nb">iter</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">start_iter</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">iterations</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="n">loss</span><span class="p">,</span> <span class="n">grad</span> <span class="o">=</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">-=</span> <span class="n">step</span> <span class="o">*</span> <span class="n">grad</span>
</pre></td></tr></tbody></table></code></pre></figure> <p>Example notebook with above example can be found <a href="https://github.com/achchg/achchg.github.io/blob/master/jupyternb/2022-09-29-Stochastic_gradient_descent.ipynb">here</a>.</p> <p>Great reference material can be found <a href="https://web.stanford.edu/~jurafsky/slp3/5.pdf">here</a></p>]]></content><author><name></name></author><category term="probability"/><category term="gradient"/><category term="review"/><summary type="html"><![CDATA[Day 7 - 8]]></summary></entry><entry><title type="html">Inverse transform sampling</title><link href="https://achchg.github.io/blog/2022/Inverse_transform_sampling/" rel="alternate" type="text/html" title="Inverse transform sampling"/><published>2022-09-28T00:00:00+00:00</published><updated>2022-09-28T00:00:00+00:00</updated><id>https://achchg.github.io/blog/2022/Inverse_transform_sampling</id><content type="html" xml:base="https://achchg.github.io/blog/2022/Inverse_transform_sampling/"><![CDATA[<p>Continuing from Day 5, I read another interesting <a href="https://stackoverflow.com/questions/5837572/generate-a-random-point-within-a-circle-uniformly">post</a> along the same line on stackoverflow. However, this time, slightly reforming the question as “How to generate a random point within a circle (uniformly)?” Eventhough the answer from <strong>aioobe</strong> on stackoverflow explained it very well, I still decided to summarize and document for my future self and also to review the concept of <strong>Inverse transform sampling</strong>.</p> <p>In order to dirctly sample from a circle without using a square and Monte Carlo simulation, we can try to gather the cumulative density function (CDF, or F(r)) and apply Inverse transform sampling to solve it.</p> <h4 id="how-to-come-up-with-cdf">How to come up with CDF?</h4> <p>As explained in the above stackoverflow, to uniformly sample from a circle we cannot solely sample \(r\) uniformly from \((0, R)\) and \(\theta\) from \((0, 2\pi)\). This is because as r is away from the center \((0, 0)\), the area being summarized given an incremental increase in \(r\) (e.g. \(d\)) also get larger, meaning that we’d need more samples to be randomly chosen, as the r increases from d to 2d, to achieve uniformly distributed sampling.</p> <p>If we consider the increase in circumference when the random radius increases from \(d\) to \(2d\), the increase in the length of the circumference from \(2 \pi d\) to \(4\pi d\) suggests that the instaneous increase in the probability is linearly to increase in random variable \(r\) as d (a.k.a. \(f(r) \propto r\))</p> <p>With the property of probability:</p> \[\int_0^R f(r) dr = \int_0^R kr dr = 1\] <p>We know that:</p> \[k\frac{R^2}{2} = 1, k = \frac{2}{R^2}\] <p>Therefore:</p> \[f(r) = \frac{2}{R^2}r, F(r) = \frac{2}{R^2}\frac{r^2}{2} = \frac{r^2}{R^2}\] <h4 id="leveraging-inverse-transform-sampling">Leveraging Inverse transform sampling!</h4> <p>You might like to check the <a href="https://en.wikipedia.org/wiki/Inverse_transform_sampling">wikipedia page</a>, but the concept is relatively simple: It might be hard to generate a random sample directly. However, if we know its CDF (\(F(x)\)), we can usually easily sample randomly from a uniform distribution (u) and apply \(F^-1(u)\) to be a random sample of X! In math:</p> \[F_x(x) = Pr(X \leq x) = u\] <p>where</p> \[u \sim U(0, 1)\] <p>then</p> \[x = F_X^{-1}(u)\] <h4 id="linking-both-pieces-together">Linking both pieces together</h4> <p>Here if we sample \(u\) uniformly from \(U(0, 1)\)</p> \[F(r) = \frac{r^2}{R^2} = u\] \[r^2 = R^2 u\] <p>As a result:</p> <ul> <li>We will sample r with the following algorithm:</li> </ul> \[r = F^{-1}(u) = R\sqrt{u}\] <ul> <li>And we will uniformly sample \(\theta\) as:</li> </ul> \[\theta = 2\pi u_1\] <p>where</p> \[u_1 \sim U(0, 1)\] <ul> <li>Transformation from polar to Cartesian coordinate:</li> </ul> \[x = r\cos(\theta)\] \[y = r\sin(\theta)\] <figure class="highlight"><pre><code class="language-python" data-lang="python"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
</pre></td><td class="code"><pre> 
<span class="n">R</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">1000</span>

<span class="k">def</span> <span class="nf">random_circle_sample</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Random unifromly sample N samples from a circle
    N: Number of simulation/samples
    R: radius of the circle
    </span><span class="sh">"""</span>
    
    <span class="n">u</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
    <span class="n">theta</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">math</span><span class="p">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">R</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
    
    <span class="n">y</span> <span class="o">=</span> <span class="n">r</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="nf">sin</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">r</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="nf">cos</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>
    
    <span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">80</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></pre></figure> <p>Example notebook with above example can be found <a href="https://github.com/achchg/achchg.github.io/blob/master/jupyternb/2022-09-28-Inverse_transform_sampling.ipynb">here</a>.</p>]]></content><author><name></name></author><category term="probability"/><category term="review"/><summary type="html"><![CDATA[Day 6]]></summary></entry></feed>